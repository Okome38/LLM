# 第2回学習レポート: RAGシステム構築

## 1. はじめに
このレポートでは、大規模言語モデル (LLM) を活用したRAG (Retrieval-Augmented Generation) システムの構築について、その理論的背景から具体的な実装、そして成果物である`rag-lecture.html`の詳細な内容までをまとめる。

## 2. RAGシステムの理論的背景
`rag-lesson-02.md`のセクション1〜7（中略部分）では、RAG（Retrieval-Augmented Generation）システムの基本的な概念、従来のLLMの課題（ハルシネーション、知識の陳腐化など）を解決するアプローチとしてRAGが有効であること、そしてその主要な構成要素であるRetrieval（情報検索）とGeneration（回答生成）の連携について解説されている。RAGは、外部の知識ベースから関連情報を検索し、それをLLMへのプロンプトに含めることで、LLMがより正確で根拠に基づいた、最新の情報を反映した回答を生成できるようにする技術である。

## 3. 実装概要
本課題では、汎用的なRAGシステムと、講義録に特化したRAGシステムの2種類を構築した。特に`rag-lecture.html`は、講義録に特化したUIとして設計されている。

**ディレクトリ構成と各ファイルの役割 (rag-lesson-02.mdより抜粋)**
```
llm-rag-learning-template/
├── js/
│   ├── llm-client.js        （LLM APIとの通信担当）
│   ├── vector-search.js     （ベクトル検索エンジンのコアロジック）
│   ├── rag-system.js        （RAGのパイプライン全体を制御）
│   ├── app-rag.js           （汎用UIとRAGシステムの連携役）
│   └── app-rag-lecture.js   （講義録UIとRAGシステムの連携役）
├── data/
│   ├── sample-documents.json  （汎用RAG向けのサンプル文書）
│   └── lecture-documents.json （講義録RAG向けの専門文書）
├── rag.html                 （汎用システムのUI）
└── rag-lecture.html         （講義録に特化したシステムのUI）
```
本レポートでは、上記の中でも特に`rag-lecture.html`とそれに関連する実装に焦点を当てて詳述する。

## 4. ベクトル検索エンジンの実装 (`vector-search.js`)
RAGの根幹である「検索」を担うベクトル検索エンジンとして、`VectorSearchEngine`クラスが実装されている。このクラスは、テキストデータを意味的なベクトル空間に配置し、類似度に基づいて検索する機能を提供する。

### データ構造
-   `this.documents`: 元の文書オブジェクト（id, text, metadata）を格納する配列。
-   `this.embeddings`: `addDocument`が呼び出された際、各文書から生成された埋め込みベクトル（数値配列）を格納する配列。
これら2つの配列は並列に管理され、`documents[i]`と`embeddings[i]`が常に対応するペアとなる設計である。これにより、類似度計算後、インデックス`i`を介して元の文書情報へ高速にアクセスできる。

### `cosineSimilarity(vectorA, vectorB)`: 類似度計算の核心
2つのベクトル間の類似度を計算するためにコサイン類似度が採用されている。この手法は、ベクトルの「大きさ」ではなく「向き」に着目する点が特徴である。
```javascript
// 計算式
similarity = (vectorA・vectorB) / (||vectorA|| * ||vectorB||)
```
-   **分子（内積）**: 2つのベクトルがどれだけ同じ方向を向いているかを示す。
-   **分母（ノルムの積）**: 各ベクトルの長さを正規化（大きさを1に揃える）する役割を持つ。これにより、文書の長さに影響されにくく、純粋に「意味の内容」の類似性を評価できる。

### `search(query, topK)`: 検索処理のステップ
1.  **クエリのベクトル化**: `llm.getEmbedding(query)`を呼び出し、ユーザーの質問文字列を、文書と同じベクトル空間上のベクトルに変換する。
2.  **全文書との類似度計算**: `this.embeddings.map()`を用いて、保持している全文書のベクトルとクエリベクトルとのコサイン類似度を一つずつ計算する。
3.  **ソート**: 計算結果を類似度の降順（高いものが先頭）に並べ替える。
4.  **結果の返却**: 上位K件の結果のみを切り出して返す。

## 5. RAGシステムの実装 (`rag-system.js`)
`VectorSearchEngine`を内部で利用し、検索から回答生成までの一連の処理（パイプライン）を統合・制御する`RAGSystem`クラスが実装されている。

### `initialize(documents)`: 事前準備
アプリケーション起動時に一度だけ呼び出され、文書を一つずつ`searchEngine.addDocument()`に渡し、非同期でベクトル化とインデックス構築を行う。

### `query(question, options)`: 質問応答パイプライン
1.  **文書検索**: `searchEngine.search()`を呼び出し、質問に意味的に最も関連する文書群を取得する。
2.  **コンテキスト構築 (`buildContext`)**: 取得した文書群を、LLMが理解しやすいように`[文書1]... [文書2]...`という明確な形式の文字列（コンテキスト）に整形する。
3.  **プロンプトエンジニアリング (`buildPrompt`)**: RAGの性能を最大化するため、以下の構造を持つプロンプトテンプレートを設計。
    ```
    以下の文書を参考にして、質問に答えてください。

    参考文書:
    ${context}
    
    質問: ${question}
    
    回答:
    ```
    このテンプレートは、LLMに対し「あなたの内部知識ではなく、提供された参考文書に基づいて回答せよ」という強い指示を与え、ハルシネーションを抑制し、根拠に基づいた回答を生成させる。
4.  **LLMによる回答生成**: 最終的に生成されたプロンプトを`llm.chat()`に渡し、回答を生成させる。

### `displayRAGResult(result)`: 動的な結果表示
JavaScriptのテンプレートリテラルを全面的に採用し、取得した結果オブジェクトから動的にHTMLを生成する。`result.sources.map()`を用いて複数の参考文書を効率的にループ処理し、各文書に対応するHTMLブロックを生成している。

## 6. UI構成と連携: `rag-lecture.html`の詳細
ユーザーインターフェース（UI）とバックエンドロジックの連携は、`async/await`を駆使した非同期処理制御が鍵となる。`rag-lecture.html`は、講義録に特化したRAGシステムのためのUIを提供する。

### `rag-lecture.html`の構造
-   **タイトル**: `<h1>🔍 RAG質問応答システム (講義録Ver.)</h1>`
-   **入力フィールド**: `id="question"`を持つ`<input>`タグで、ユーザーが質問を入力する。
-   **質問ボタン**: `onclick="askRAG()"`を持つ`<button>`タグで、質問処理をトリガーする。
-   **結果表示領域**: `id="rag-result"`を持つ`<div>`タグで、RAGシステムからの回答が表示される。
-   **CSS**: `link rel="stylesheet" href="css/style.css"`によって共通のスタイルが適用されている。
-   **JavaScriptファイルの読み込み順序**:
    1.  `js/config.js`
    2.  `js/llm-client.js`
    3.  `js/vector-search.js`
    4.  `js/rag-system.js`
    5.  `js/app-rag-lecture.js` （UIとRAGシステムの連携役）

### `app-rag-lecture.js`の処理フロー
-   **非同期初期化**: `DOMContentLoaded`イベントリスナー内で`async`関数を使用し、`data/lecture-documents.json`を非同期で読み込み、`ragSystem.initialize`を呼び出してRAGシステムのインデックスを構築する。これにより、UIの応答性を保ちつつバックグラウンドでシステム準備が進められる。
-   **ユーザー操作への応答 (`askRAG`)**:
    -   `async`関数として定義され、ユーザーが「質問する」ボタンをクリックすると実行される。
    -   入力された質問を`ragSystem.query()`に渡し、`await`で回答の生成を待機する。
    -   **ユーザー体験の向上**: 質問処理中に「回答を生成中...」というローディングメッセージを表示し、処理完了後にRAGシステムからの結果で上書きする。
    -   **堅牢なエラーハンドリング**: `try...catch`ブロックで囲むことで、システムのエラー発生時にもユーザーに適切なフィードバックを提供し、アプリケーション全体のクラッシュを防ぐ。

## 7. 実習課題の成果
`rag-lesson-02.md`に記載された実習課題において、特に`rag-lecture.html`に関連する部分の成果は以下の通りである。

-   **課題1（文書追加）**: `data/lecture-documents.json`に、自身の専門分野に関する講義録の要約が追加されることを想定している。
-   **課題3（RAGと通常LLMの比較）**: `rag-lecture.html`上で専門的な質問（例: 「B木のデータ追加処理」）を行った際、RAGシステムが`lecture-notes-documents.json`から関連文書を検索し、それに基づいて正確かつ具体的な回答を生成できることが確認されている。これは、通常のLLMが一般的な回答に留まるのと対照的である。
-   **課題4（期末試験対策RAGアプリ）**: `rag-lecture.html`とそれに関連するシステムは、文書データ（JSONファイル）を入れ替えるだけで、任意の科目に特化したQAシステムとして機能することが確認されている。これにより、RAGの高い拡張性と実践的な応用可能性が示された。
