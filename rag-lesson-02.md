# 大規模言語モデルの体験 第2回  
## RAG（Retrieval-Augmented Generation）システム構築 (詳細レポート)

- **日時**：2026/1/8  
- **場所**：専攻科講義室1  
- **授業時間**：180分  
- **担当教員**：森田 海  

---

## (中略: セクション1〜7は変更なし)

---

## 8. 実装概要

### ディレクトリ構成と各ファイルの役割
本課題では、汎用的なRAGシステムと、講義録に特化したRAGシステムの2種類を構築した。
```
llm-rag-learning-template/
├── js/
│   ├── llm-client.js        （第1回で作成。LLM APIとの通信担当）
│   ├── vector-search.js     （新規。ベクトル検索エンジンのコアロジック）
│   ├── rag-system.js        （新規。RAGのパイプライン全体を制御）
│   ├── app-rag.js           （新規。汎用UIとRAGシステムの連携役）
│   └── app-rag-lecture.js   （新規。講義録UIとRAGシステムの連携役）
├── data/
│   ├── sample-documents.json  （汎用RAG向けのサンプル文書）
│   └── lecture-documents.json （講義録RAG向けの専門文書）
├── rag.html                 （汎用システムのUI）
└── rag-lecture.html         （講義録に特化したシステムのUI）
```
本レポートでは、これらの実装内容について、アルゴリズムや処理フローの観点から詳述する。

---

## 9. ベクトル検索エンジンの実装 (`vector-search.js`)

RAGの根幹である「検索」を担うベクトル検索エンジンとして、`VectorSearchEngine`クラスを実装した。このクラスは、テキストデータを意味的なベクトル空間に配置し、類似度に基づいて検索する機能を提供する。

### データ構造
- `this.documents`: 元の文書オブジェクト（id, text, metadata）を格納する配列。
- `this.embeddings`: `addDocument`が呼び出された際、各文書から生成された埋め込みベクトル（数値配列）を格納する配列。
- これら2つの配列は並列に管理され、`documents[i]`と`embeddings[i]`が常に対応するペアとなる設計である。これにより、類似度計算後、インデックス`i`を介して元の文書情報へ高速にアクセスできる。

### `cosineSimilarity(vectorA, vectorB)`: 類似度計算の核心
2つのベクトル間の類似度を計算するためにコサイン類似度を採用した。この手法は、ベクトルの「大きさ」ではなく「向き」に着目する点が特徴である。
```
// 計算式
similarity = (vectorA・vectorB) / (||vectorA|| * ||vectorB||)
```
- **分子（内積）**: 2つのベクトルがどれだけ同じ方向を向いているかを示す。
- **分母（ノルムの積）**: 各ベクトルの長さを正規化（大きさを1に揃える）する役割を持つ。これにより、文書の長さに影響されにくく、純粋に「意味の内容」の類似性を評価できる。

### `search(query, topK)`: 検索処理のステップ
1.  **クエリのベクトル化**: `llm.getEmbedding(query)`を呼び出し、ユーザーの質問文字列を、文書と同じベクトル空間上のベクトルに変換する。
2.  **全文書との類似度計算**: `this.embeddings.map()`を用いて、保持している全文書のベクトルとクエリベクトルとのコサイン類似度を一つずつ計算する。この処理は計算量O(N)（Nは文書数）となり、システムのスケーラビリティにおける主要なボトルネックである。
3.  **ソート**: `similarities.sort((a, b) => b.similarity - a.similarity)`により、計算結果を類似度の降順（高いものが先頭）に並び替える。
4.  **結果の返却**: `slice(0, topK)`を用いて、上位K件の結果のみを切り出して返す。

---

## 10. RAGシステムの実装 (`rag-system.js`)

`VectorSearchEngine`を内部で利用し、検索から回答生成までの一連の処理（パイプライン）を統合・制御する`RAGSystem`クラスを実装した。

### `initialize(documents)`: 事前準備
-   アプリケーション起動時に一度だけ呼び出される。
-   `for...of`ループを用いて文書を一つずつ`searchEngine.addDocument()`に渡し、非同期でベクトル化とインデックス構築を行う。この初期化処理は、多数の文書を扱う場合はAPI呼び出しに時間がかかるため、ユーザーが操作可能になる前の「前処理」として重要である。

### `query(question, options)`: 質問応答パイプライン
1.  **文書検索**: `searchEngine.search()`を呼び出し、質問に意味的に最も関連する文書群を取得する。
2.  **コンテキスト構築 (`buildContext`)**: 取得した文書群を、LLMが理解しやすいように`[文書1]... [文書2]...`という明確な形式の文字列（コンテキスト）に整形する。
3.  **プロンプトエンジニアリング (`buildPrompt`)**: RAGの性能を最大化するため、以下の構造を持つプロンプトテンプレートを設計した。
    ```
    以下の文書を参考にして、質問に答えてください。

    参考文書:
    ${context}
    
    質問: ${question}
    
    回答:
    ```
    このテンプレートは、LLMに対し「あなたの内部知識ではなく、提供された参考文書に基づいて回答せよ」という強い指示（Instruction）を与える役割を持つ。これにより、ハルシネーションを抑制し、根拠に基づいた回答を生成させることができる。
4.  **LLMによる回答生成**: 最終的に生成されたプロンプトを`llm.chat()`に渡し、回答を生成させる。

### `displayRAGResult(result)`: 動的な結果表示
-   JavaScriptのテンプレートリテラル（バッククォート `` ` ``）を全面的に採用し、取得した結果オブジェクトから動的にHTMLを生成する。
-   `result.sources.map()`を用いることで、複数の参考文書を効率的にループ処理し、各文書に対応するHTMLブロックを生成している。
-   `onmouseover` / `onmouseout`属性を直接HTMLに埋め込むことで、CSSの`:hover`疑似クラスだけでは実現しにくい、影や位置の変化といったインタラクティブなUI効果を付与した。

---

## 11. UI構成と連携

ユーザーインターフェース（UI）とバックエンドロジックの連携は、`async/await`を駆使した非同期処理制御が鍵となる。

### `app-rag.js` / `app-rag-lecture.js` の処理フロー
1.  **非同期初期化**: `DOMContentLoaded`イベントリスナー内で`async`関数を使用。`fetch`によるデータファイルの読み込みと、`ragSystem.initialize`によるインデックス構築という、時間のかかるI/O処理を非同期で実行する。これにより、ページのレンダリングをブロックすることなく、バックグラウンドでシステムの準備が進行する。
2.  **ユーザー操作への応答 (`askRAG`)**:
    -   この関数も`async`として定義されており、`ragSystem.query()`の完了を`await`で待機する。
    -   **ユーザー体験の向上**: `query`呼び出しの直前に「回答を生成中...」というローディングメッセージを表示し、処理の完了後に結果で上書きする。これにより、ユーザーはシステムが動作中であることを明確に認識でき、待機時間のストレスが軽減される。
    -   **堅牢なエラーハンドリング**: `try...catch`ブロックで全体の処理を囲む。API通信のエラーやデータ処理の失敗など、予期せぬ問題が発生した場合でも、`catch`ブロックでエラーを捕捉し、ユーザーに「エラーが発生しました」というフィードバックを返すことで、アプリケーション全体のクラッシュを防いでいる。

### 役割分担による拡張性
本課題では、データソースが異なるだけの2つのRAGシステムを、UI連携用の`app-*.js`ファイルを分けるだけで実現した。`RAGSystem`や`VectorSearchEngine`といったコアロジックは共通化されており、データソースの指定という「設定」に近い部分のみを分離することで、高い再利用性と拡張性を確保した設計となっている。

---

## 12. 実習課題の成果

講義で指示された課題に対し、以下の実装と確認を行った。

-   **課題1（文書追加）**: `data/lecture-documents.json`に、自身の専門分野である「情報構造論」に関する講義録の要約を複数追加した。

-   **課題2（検索結果改善）**: `rag-system.js`の`displayRAGResult`メソッドを大幅に改修し、前述の通り、類似度に基づいた色分け、キーワードハイライト、アイコン付きのメタデータ表示機能を実装した。これにより、検索結果の可読性が劇的に向上した。

-   **課題3（RAGと通常LLMの比較）**: `rag-lecture.html`上で「B木のデータ追加処理」のような専門的な質問を行った。通常のLLMが一般的な回答しかできないのに対し、RAGシステムは`lecture-documents.json`から適切な講義資料を検索し、それを基に正確かつ具体的な回答を生成することを確認した。

-   **課題4（期末試験対策RAGアプリ）**: 本課題で構築した**`rag-lecture.html`とそれに関連するシステム**が、そのまま期末試験対策アプリとして機能することを確認した。この構成により、文書データ（JSONファイル）を入れ替えるだけで、任意の科目に特化したQAシステムを容易に構築できるという、RAGの拡張性の高さを実践的に理解できた。