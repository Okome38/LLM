# 第4回授業課題：適応的学習支援AIシステム開発レポート

## 1. はじめに

本レポートは、第4回授業課題「適応的学習支援AIシステム開発」に対応し、ユーザーが開発した（または開発途中の）Webアプリケーションの理論的背景と実際の実装について詳細にまとめたものです。

本課題の目標は、RAG（Retrieval Augmented Generation）、オントロジー、ファクトチェックといった技術を組み合わせ、学習者の状態に合わせて支援内容を変化させる適応的な学習支援AIシステムを構築することにありました。

本レポートでは、`index.html`をUIとして、それを支えるデータ構成 (`data/my-documents.json`, `data/my-ontology.json`)、メインロジック (`js/my-app.js`)、およびバックエンドの動作を担う`server.js`について、その設計思想と実装、そして開発過程で発生した問題とその解決策を解説します。

## 2. システムの目標と「第4回」課題への対応

「第4回.md」で提示された主要な目標は以下の3点です。

1.  **知識検索 (RAG)**: 学習資料から適切な情報を取得する。
2.  **適応的支援 (オントロジー)**: 学習者に合わせた支援（前提知識チェック、難易度適応、関連概念提示、段階的ヒント）を1つ以上実装する。
3.  **情報検証 (ファクトチェック)**: 信頼性を担保する。

本システムは、これらの要件を満たすことを目指して設計・実装されています。ユーザーが質問を入力すると、RAGシステムが関連情報を検索し、その回答を生成します。同時に、オントロジーを活用して関連概念や前提知識を提示し、学習者の理解を深める支援を行います。さらに、ファクトチェック機能により、提供された情報の信頼性を外部ソース（学術論文、書籍、Web）で検証する手段を提供します。

## 3. 主要コンポーネントの設計と実装

### 3.1. `index.html` (ユーザーインターフェース)

`index.html` は、ユーザーがAIと対話するためのメインインターフェースを提供します。
主な機能要素は以下の通りです。

*   **タイトルとサブタイトル**: アプリケーションの目的を提示します。
*   **質問入力セクション**: ユーザーが質問を入力するテキストフィールド (`#question-input`) と、質問を送信するボタン (`#ask-btn`) を配置します。初期状態では無効化されており、システムの初期化が完了すると有効になります。
*   **結果表示コンテナ**: AIの回答、適応的支援、検証結果などが動的に表示される領域 (`#result-container`) です。
*   **スタイル**: `css/style.css` を読み込み、視覚的な一貫性とユーザーエクスペリエンスを向上させます。
*   **依存スクリプト**: 以下のJavaScriptファイルを読み込み、アプリケーションの機能を提供します。
    *   `js/config.js`
    *   `js/secrets.js` (APIキー管理のため)
    *   `js/llm-client.js`
    *   `js/vector-search.js`
    *   `js/ontology.js`
    *   `js/concept-extractor.js`
    *   `js/semantic-rag.js`
    *   `js/web-search-client.js`
    *   `js/fact-checker.js`
    *   `js/my-app.js` (メインロジック)

### 3.2. データ構成 (``data/vocal_technique_documents.json``, ``data/vocal_technique_ontology.json``)

システムの中核をなすのは、知識ベースと概念関係を定義するJSONデータファイルです。本システムの開発において、私は学習支援の核となる知識ベースと概念ネットワークを設計し、`data/vocal_technique_documents.json`および`data/vocal_technique_ontology.json`として構築しました。これらのデータは、Web検索で収集した発声技術に関する情報を含む、多様な学習コンテンツを構造化しています。

#### ``data/vocal_technique_documents.json`` (知識ベース)

このファイルは、RAGシステムが参照する学習資料を構造化して格納します。各ドキュメントは以下のフィールドを持ちます。

*   `id`: ドキュメントの一意の識別子。
*   `title`: ドキュメントのタイトル。
*   `content`: ドキュメントの本文。ここに含まれる内容がRAGの検索対象となります。
*   `category`: ドキュメントのカテゴリ（例: "声区", "基礎"）。
*   `level`: 対象となる学習者のレベル（例: "beginner", "intermediate", "advanced"）。
*   `prerequisites`: このドキュメントを理解するための前提知識の概念IDリスト。
*   `keywords`: ドキュメントの内容を表すキーワードリスト。

本知識ベースは、歌唱の基礎から応用まで、幅広い発声技術を網羅するように設計しました。具体的には、以下のドキュメントを定義しています。

*   **基礎技術**: 腹式呼吸 (`doc001`)、共鳴 (`doc002`) など、歌唱の土台となる概念をカバーします。
*   **声区**: チェストボイス (`doc003`)、ヘッドボイス (`doc004`)、ミックスボイス (`doc005`)、そしてより専門的なベルティングボイス (`doc009`) といった様々な声の出し方に関する技術を構造化しました。特にベルティングボイスは、強い声量を保ちながら高音域を力強く響かせる歌唱方法として、その特徴と習得方法を詳細に記述しています。
*   **表現技術**: ビブラート (`doc006`) など、歌唱に深みを与える技術が含まれます。
*   **練習方法**: ロングトーン (`doc007`)、リップロール (`doc008`) など、実践的な練習法を提供します。
*   **音響技術**: シンガーズフォルマント (`doc010`) は、熟練した歌手の声に共通する音響的特徴として定義しました。これは、約2500Hzから3500Hzの周波数帯域にエネルギーが集中する現象であり、声の明瞭性や通りやすさを向上させる役割を持ちます。

これらのドキュメントは、それぞれ適切な`category`、`level`、`prerequisites`、`keywords`が設定されており、RAGシステムが効率的かつ正確に情報を検索できるよう最適化されています。

#### ``data/vocal_technique_ontology.json`` (オントロジー)

オントロジーは、学習概念間の関係を定義し、適応的学習支援の基盤となります。
`concepts` オブジェクトと `relations` 配列で構成されます。

*   **`concepts`**: 各学習概念の定義を含みます。
    *   `concept_id`: 概念の一意のID（例: "breathing", "mixed-voice"）。
    *   `label`: 概念の表示名。
    *   `description`: 概念の簡潔な説明。
    *   `level`: 概念の難易度レベル。
    *   `prerequisites`: その概念を理解するために必要な他の概念のIDリスト。
    *   `relatedConcepts`: 関連する他の概念のIDリスト。
    *   `nextSteps`: その概念を学んだ後に学ぶべき概念のIDリスト。

*   `relations`: 概念間の具体的な関係（前提、関連、次のステップ）と、その関係の強さ (`strength`) を定義します。

オントロジーでは、歌唱に関する様々な概念とその関係性を詳細に定義しました。これにより、学習者の現在地に応じた適応的な学習支援が可能になります。主要な概念と定義した関係性は以下の通りです。

*   **基礎概念**: 腹式呼吸 (`breathing`) や共鳴 (`resonance`) は、歌唱の土台となるため、多くの他の概念の`prerequisites`として設定されています。
*   **声区と技術**: チェストボイス (`chest-voice`)、ヘッドボイス (`head-voice`)、ミックスボイス (`mixed-voice`) といった声区の概念を定義し、それぞれが持つ特性と相互の`prerequisites`を設定しました。特に、**ベルティング** (`belting`) はミックスボイス、腹式呼吸、共鳴を前提とする高度な技術として位置づけ、チェストボイスやヘッドボイスとの関連性も明示しています。
*   **音響学的概念**: **シンガーズフォルマント** (`singers-formant`) は、共鳴やヘッドボイスを前提とする音響学的な特徴として定義しました。これはミックスボイスやビブラートといった表現技術とも関連付けています。
*   **練習方法と表現**: リップロール (`lip-roll`) やロングトーン (`long-tone`)、ビブラート (`vibrato`) などの実践的な練習方法や表現技術も概念化し、他の概念との`nextSteps`や`relatedConcepts`を設定しました。

これらの詳細な概念定義と関係性（`prerequisite`, `related`, `nextStep`）により、システムは学習者の質問に対して、適切な前提知識の提示、関連概念の紹介、次に学ぶべきステップの示唆といった、パーソナライズされた学習パスを動的に生成できるようになります。

### 3.3. `js/my-app.js` (メインアプリケーションロジック)

`js/my-app.js` は、アプリケーションの主要なクライアントサイドロジックをカプセル化する `MyLearningApp` クラスを定義します。

*   **`initialize()` メソッド**:
    *   システムの起動時に呼び出され、必要なデータの読み込みとコンポーネントの初期化を行います。
    *   **修正経緯と内容**: 当初、`fetch("data/my-documents.json")` のような相対パスでデータファイルを読み込もうとした際に、`TypeError: Failed to fetch` エラーが発生しました。これは、Webサーバーを介さずにローカルファイルとして`index.html`を開いた場合、`my-app.js`のパス解決が相対的に行われるため、`js/data/my-documents.json`のような誤ったパスを参照していたためです。この問題を解決するため、パスを`../data/vocal_technique_documents.json`および`../data/vocal_technique_ontology.json`に修正しました。
*   **`handleQuestion()` メソッド**:
    *   ユーザーの質問を受け取り、RAGシステム (`SemanticRAGSystem`) を介して回答を生成します。
    *   生成された回答と関連ソース、そして適応的支援を返します。
*   **`generateAdaptiveSupport()` メソッド**:
    *   ユーザーの質問やRAGの検索結果に基づいて、オントロジー (`LearningOntology`) を活用し、前提知識、関連概念、次に学ぶべきステップなどの適応的支援を生成します。
*   **`displayResult()` メソッド**:
    *   AIの回答と適応的支援をHTML要素として整形し、`index.html`の`#result-container`に表示します。
    *   ファクトチェック機能のUI (`#verification-area`) もこの段階で生成されます。

### 3.4. `server.js` (バックエンドサーバー)

`server.js` はNode.jsとExpressフレームワークを用いて、静的ファイルの配信とWeb検索APIの提供を行います。

*   **目的と役割**:
    *   クライアントサイドのHTML、CSS、JavaScriptファイルなどをWebブラウザに提供します。
    *   Tavily APIを利用したWeb検索機能（`/api/web-search`）をバックエンドで実行し、クライアントからの直接的なAPIキー露出を防ぎます。
*   **Expressのセットアップと静的ファイル配信**:
    *   `express` モジュールをインポートし、`app` インスタンスを作成します。
    *   `app.use(express.static(path.join(__dirname)))` により、サーバーのルートディレクトリにあるファイル（`index.html`, `js/`, `data/`, `css/`など）を静的ファイルとして公開します。
    *   ポート3000でリッスンし、`http://localhost:3000/index.html` でアプリケーションにアクセスできるように設定しています。
*   **Web検索APIエンドポイント (`/api/web-search`)**:
    *   クライアントからのWeb検索リクエストを受け取り、Tavily APIに転送し、結果を整形してクライアントに返します。
    *   レートリミット機能 (`express-rate-limit`) と学生ごとの使用量追跡 (`checkStudentUsage`) を組み込んでいます。
*   **`dotenv`による環境変数管理**:
    *   `require('dotenv').config();` を`server.js`の冒頭に追加することで、`.env`ファイルに記述された`TAVILY_API_KEY`のような機密情報を環境変数として安全に読み込むことができます。これにより、APIキーが直接コードに埋め込まれることを防ぎ、セキュリティを向上させます。
*   **ルーティング順序修正の経緯と内容**:
    *   当初、`app.post('/api/web-search', ...)` のルーティング定義が`app.listen(...)`の後ろに配置されていました。Expressでは`app.listen`の実行前に全てのルーティングを定義する必要があるため、サーバー起動時にWeb検索APIが正しく登録されず、クライアントからのリクエストに応答できない問題が発生する可能性がありました。このため、`app.post`ルーティングの定義を`app.listen`の前に移動させ、Expressの動作規約に沿うように修正しました。
*   **サーバー起動手順**:
    1.  `npm install express express-rate-limit dotenv node-fetch` で依存関係をインストール。
    2.  `.env` ファイルに `TAVILY_API_KEY=YOUR_TAVILY_API_KEY_HERE` を設定。
    3.  `node server.js` でサーバーを起動。
    4.  ブラウザで `http://localhost:3000/index.html` にアクセス。

## 4. 適応的学習支援の実装詳細

本システムにおける適応的学習支援は、RAGとオントロジーの連携、およびファクトチェック機能によって実現されます。

*   **RAGの役割**: `semanticQuery`メソッドは、ユーザーの質問に対し、`vocal_technique_documents.json`から最も関連性の高い情報を抽出し、LLMを用いて自然言語の回答を生成します。これにより「何を教えるか」が質問内容に応じて動的に決定されます。
*   **オントロジーを活用した適応的支援**: `generateAdaptiveSupport`メソッドは、RAGが特定した概念を元に、`vocal_technique_ontology.json`から関連する学習支援情報を提供します。
    *   **前提知識チェック**: 質問内容に関連する概念の前提知識を提示し、学習の順序をガイドします。
    *   **関連概念提示**: 質問から派生する関連概念を提示し、学習者の興味を拡張します。
    *   私が設計したオントロジーは、ベルティングやシンガーズフォルマントを含む様々な歌唱技術の概念とその相互関係を定義しており、これらの支援メカニズムによって学習者に提示されます。例えば、ベルティングを学ぶ前にはミックスボイスが必要であることや、シンガーズフォルマントが共鳴やヘッドボイスと深く関連していることなどが、オントロジーの定義に基づき示唆されます。
*   **ファクトチェック機能**: `FactChecker`クラスは、`WebSearchClient`を利用して、生成された回答の信頼性を外部のWeb情報源で検証します。これにより、学習者は情報の正確性を自身で確認する手段を持つことができます。

## 5. 結論と今後の展望

本レポートで解説したシステムは、「第4回.md」で提示された適応的学習支援AIの基本要件を満たしています。UI (`vocal_learning_app.html`)、知識ベース (`vocal_technique_documents.json`, `vocal_technique_ontology.json`)、クライアントロジック (`my-app.js`)、そしてバックエンドサーバー (`server.js`) が連携し、ユーザーの質問に対してRAGによる回答生成、オントロジーによる適応的学習支援、そしてファクトチェックによる情報検証機能を提供します。

開発過程では、クライアントサイドの`fetch`パスの問題や`server.js`の起動順序の問題などが発生しましたが、これらは修正され、システムは安定して動作するようになりました。特に、私はベルティングとシンガーズフォルマントを含む専門的な歌唱技術の知識を知識ベース (`vocal_technique_documents.json`) とオントロジー (`vocal_technique_ontology.json`) に最初から構築し、システムの学習コンテンツを充実させました。

今後の展望としては、以下の点が挙げられます。

*   **適応的支援のさらなる強化**: 学習者の過去の学習履歴や進捗状況を考慮に入れた、よりパーソナライズされた支援機能の追加。
*   **UI/UXの改善**: 学習者のエンゲージメントを高めるためのUIデザインの洗練やインタラクティブな要素の追加。
*   **知識ベースの拡張と自動更新**: 新しい学習コンテンツを継続的に取り込み、知識ベースを自動的に更新するメカニズムの導入。
*   **LLMとの連携強化**: より高度な質問理解や回答生成、学習者の疑問点の推測能力の向上。

本システムは、学習者一人ひとりのニーズに合わせた柔軟な学習体験を提供する可能性を秘めており、今後の発展が期待されます。
